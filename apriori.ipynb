{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    '''\n",
    "    输入：无\n",
    "    功能：产生简单的数据集\n",
    "    输出：dataset\n",
    "    '''\n",
    "    return [['A','C','D'],['B','C','E'],['A','B','C','E'],['B','E']]  #每条是一个交易，每个交易里面的数字代表商品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createC1(dataset):\n",
    "    '''\n",
    "    输入：数据集\n",
    "    功能：构建1-项集。即所有独立的商品。\n",
    "    '''\n",
    "    C1 = []\n",
    "    for transction in dataset:\n",
    "        #print transction\n",
    "        for item in transction:\n",
    "            if not [item] in C1:  # 保证商品不重复\n",
    "                C1.append([item]) # 使用列表作为C1元素是因为后续需要使用集合操作\n",
    "    C1.sort()\n",
    "    return  map(frozenset,C1) # 用frozenset是为了保证可以作为字典的key去查询support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scanDataSet(DataSet,Ck,minSupport=0.5):\n",
    "    '''\n",
    "    输入：DataSet应为每条记录是set类型数据（被用于判断是否是其子集操作），Ck中的每个项集为frozenset型数据（被用于字典关键字）\n",
    "         Ck为候选频繁项集，minSupport为判断是否为频繁项集的最小支持度（认为给定）\n",
    "    功能：从候选项集中找出支持度support大于minSupport的频繁项集\n",
    "    输出：频繁项集集合returnList,以及频繁项集对应的支持度support\n",
    "    '''\n",
    "    subSetCount = {} #\n",
    "    for transction in DataSet:#取出数据集dataset中的每行记录\n",
    "        for subset in Ck:#取出候选频繁项集Ck中的每个项集\n",
    "            if subset.issubset(transction):#判断Ck中项集是否是数据集每条记录数据集合中的子集\n",
    "                if not subSetCount.has_key(subset): # 这个项集是否是第一次出现\n",
    "                    subSetCount[subset] = 1\n",
    "                else:\n",
    "                    subSetCount[subset] += 1\n",
    "    numItem = float(len(DataSet))\n",
    "    returnList =[]\n",
    "    returnSupportData = {}\n",
    "    for key in subSetCount:\n",
    "        support = subSetCount[key]/numItem\n",
    "        if support >= minSupport:\n",
    "            returnList.insert(0,key)\n",
    "            returnSupportData[key] = support\n",
    "    return returnList,returnSupportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCk(Lk,k):\n",
    "    '''\n",
    "    根据输入的集合列表，创建k-项集\n",
    "    '''\n",
    "    returnList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1,lenLk):\n",
    "            L1 = list(Lk[i])[:k-2];L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort();L2.sort()\n",
    "            if L1 == L2:\n",
    "                '''\n",
    "                只需取前k-2个元素相等的候选频繁项集即可组成元素个数为k+1的候选频繁项集！！\n",
    "                比如：k=3时，{A,B}|{A,C} = {A,B,C};与{A,B}|{B,C} = {A,B,C}一样，因此无需重复append\n",
    "                '''\n",
    "                returnList.append(Lk[i] | Lk[j])    \n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apriori(dataset,minSupport = 0.5):\n",
    "    C1 = createC1(dataset)\n",
    "    DataSet = map(set,dataset)\n",
    "    L1,returnSupportData = scanDataSet(DataSet,C1,minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        #由上一层的频繁项集，形成下一层没有重复的频繁项集，下一层候选频繁项集中元素个数会比上一时刻的多1\n",
    "        Ck = createCk(L[k-2],k)\n",
    "        #从候选频繁项集中选出支持度大于minsupport的频繁项集Lk\n",
    "        Lk,supportLk = scanDataSet(DataSet,Ck,minSupport)\n",
    "        #将该频繁项集及其支持度添加到returnSupportData字典中记录，其中频繁项集为关键字，支持度为关键字所对应的项\n",
    "        returnSupportData.update(supportLk)\n",
    "        #将频繁项集添加到列表L中记录\n",
    "        L.append(Lk)\n",
    "        #逐一增加频繁项集中的元素个数\n",
    "        k += 1\n",
    "    return L, returnSupportData  #返回所有频繁项集，和其support数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------------------关联规则生成函数--------------#\n",
    "def generateRules(L,supportData,minConference = 0.7):\n",
    "    bigRuleList = []\n",
    "    for i in range(1,len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset(item) for item in freqSet] # H就是等待评估的后件\n",
    "            rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConference)\n",
    "    return bigRuleList\n",
    "\n",
    "#用来计算所有2项频繁项的confidence\n",
    "def calculationConf(freqSet, H, supportData,brl,minConference=0.7):\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet - conseq]\n",
    "        if conf >= minConference:\n",
    "            print freqSet-conseq,'-->',conseq,'conf:',conf\n",
    "            brl.append((freqSet-conseq,conseq,conf))\n",
    "            prunedH.append(conseq) # 将符合标准的后件保存\n",
    "    return prunedH \n",
    "\n",
    "#用来计算所有2项以上的频繁项的confidence\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConference):\n",
    "    m = len(H[0])\n",
    "    while (len(freqSet) > m):  # 当频繁项的长度等于后件的长度，停止\n",
    "        H = calculationConf(freqSet,H,supportData,brl,minConference) #Hm即为prunedH\n",
    "        if (len(H)>1):  # 如果满足最小confidence的后件个数大于1，把后件中的元素的个数+1，循环。如:本来是b,e->c,接下来计算b->c,e\n",
    "            H = createCk(H, (m+1)) #利用函数createCk生成包含m+1个元素的后件\n",
    "            m+=1\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset(['C']) --> frozenset(['A']) conf: 0.666666666667\n",
      "frozenset(['A']) --> frozenset(['C']) conf: 1.0\n",
      "frozenset(['B']) --> frozenset(['C']) conf: 0.666666666667\n",
      "frozenset(['C']) --> frozenset(['B']) conf: 0.666666666667\n",
      "frozenset(['E']) --> frozenset(['B']) conf: 1.0\n",
      "frozenset(['B']) --> frozenset(['E']) conf: 1.0\n",
      "frozenset(['E']) --> frozenset(['C']) conf: 0.666666666667\n",
      "frozenset(['C']) --> frozenset(['E']) conf: 0.666666666667\n",
      "frozenset(['B', 'E']) --> frozenset(['C']) conf: 0.666666666667\n",
      "frozenset(['C', 'E']) --> frozenset(['B']) conf: 1.0\n",
      "frozenset(['C', 'B']) --> frozenset(['E']) conf: 1.0\n",
      "frozenset(['E']) --> frozenset(['C', 'B']) conf: 0.666666666667\n",
      "frozenset(['B']) --> frozenset(['C', 'E']) conf: 0.666666666667\n",
      "frozenset(['C']) --> frozenset(['B', 'E']) conf: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset=loadDataSet()\n",
    "    L,returnSupportData = apriori(dataset,minSupport=0.5) \n",
    "    rule = generateRules(L,returnSupportData,minConference=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
